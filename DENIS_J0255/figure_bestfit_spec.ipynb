{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pymultinest\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "\n",
    "import json\n",
    "\n",
    "import corner\n",
    "\n",
    "import retrieval_base.auxiliary_functions as af\n",
    "\n",
    "def read_results(prefix, n_params):\n",
    "\n",
    "    # Set-up analyzer object\n",
    "    analyzer = pymultinest.Analyzer(\n",
    "        n_params=n_params, \n",
    "        outputfiles_basename=prefix\n",
    "        )\n",
    "    stats = analyzer.get_stats()\n",
    "\n",
    "    # Load the equally-weighted posterior distribution\n",
    "    posterior = analyzer.get_equal_weighted_posterior()\n",
    "    posterior = posterior[:,:-1]\n",
    "\n",
    "    # Read the parameters of the best-fitting model\n",
    "    bestfit = np.array(stats['modes'][0]['maximum a posterior'])\n",
    "\n",
    "    PT = af.pickle_load(prefix+'data/bestfit_PT.pkl')\n",
    "    Chem = af.pickle_load(prefix+'data/bestfit_Chem.pkl')\n",
    "\n",
    "    m_spec = af.pickle_load(prefix+'data/bestfit_m_spec.pkl')\n",
    "    d_spec = af.pickle_load(prefix+'data/d_spec.pkl')\n",
    "\n",
    "    LogLike = af.pickle_load(prefix+'data/bestfit_LogLike.pkl')\n",
    "\n",
    "    try:\n",
    "        Cov = af.pickle_load(prefix+'data/bestfit_Cov.pkl')\n",
    "    except:\n",
    "        Cov = None\n",
    "\n",
    "    int_contr_em           = np.load(prefix+'data/bestfit_int_contr_em.npy')\n",
    "    int_contr_em_per_order = np.load(prefix+'data/bestfit_int_contr_em_per_order.npy')\n",
    "    int_opa_cloud          = np.load(prefix+'data/bestfit_int_opa_cloud.npy')\n",
    "\n",
    "    f = open(prefix+'data/bestfit.json')\n",
    "    bestfit_params = json.load(f)\n",
    "    f.close()\n",
    "\n",
    "    print(posterior.shape)\n",
    "    return posterior, bestfit, PT, Chem, int_contr_em, int_contr_em_per_order, int_opa_cloud, m_spec, d_spec, LogLike, Cov, bestfit_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  analysing data from ./retrieval_outputs/DENIS_J0255_nominal_5/test_.txt\n",
      "(4331, 32)\n"
     ]
    }
   ],
   "source": [
    "res = read_results(\n",
    "    prefix='./retrieval_outputs/DENIS_J0255_nominal_5/test_', n_params=32\n",
    "    )\n",
    "posterior_1, bestfit_1, PT_1, Chem_1, int_contr_em_1, int_contr_em_per_order_1, int_opa_cloud_1, m_spec_1, d_spec_1, LogLike_1, Cov_1, bestfit_params_1 = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.117321749249977\n",
      "1.2569615071453117\n",
      "1.4571432770130421\n",
      "1.4987832601635789\n",
      "1.3448857674678545\n",
      "1.0863822730052382\n",
      "0.9556506901825463\n",
      "1.6700342566674881e-16\n"
     ]
    }
   ],
   "source": [
    "bestfit_color = plt.get_cmap('Oranges')(0.6)\n",
    "\n",
    "#orders_for_zoom_in = [2,5]\n",
    "orders_for_zoom_in = [5]\n",
    "\n",
    "hspace = 0.12\n",
    "gridspec_kw={\n",
    "    'hspace': 0.0, \n",
    "    'left': 0.08, 'right': 0.96,  \n",
    "    'bottom': 0.08, 'top': 0.95, \n",
    "    'height_ratios': [0.7,0.4*0.35, hspace, 0.4*1,0.4*0.35]\n",
    "    }\n",
    "fig, ax = plt.subplots(\n",
    "    #figsize=(10,10), nrows=3*2+2, \n",
    "    figsize=(10,7), nrows=2*2+1,    \n",
    "    gridspec_kw=gridspec_kw\n",
    "    )\n",
    "\n",
    "ax_spec = np.array(ax[0::3])\n",
    "ax_res = np.array(ax[1::3])\n",
    "for ax_i in ax[2::3]:\n",
    "    ax_i.remove()\n",
    "\n",
    "spine_lw = 1.75\n",
    "for ax_i in ax_spec:\n",
    "    ax_i.set(xticks=[])\n",
    "    ax_i.spines[['left','right','top']].set_linewidth(spine_lw)\n",
    "    \n",
    "for ax_i in ax_res:\n",
    "    ax_i.spines[['left','right','bottom']].set_linewidth(spine_lw)\n",
    "\n",
    "    ax_i.set_zorder(-1)\n",
    "\n",
    "ax_spec[0].plot(d_spec_1.wave.flatten(), d_spec_1.flux.flatten(), c='k', lw=0.5)\n",
    "for i in range(d_spec_1.n_orders):\n",
    "    for j in range(d_spec_1.n_dets):\n",
    "        ax_spec[0].plot(d_spec_1.wave[i,j], LogLike_1.f[i,j]*m_spec_1.flux[i,j], c=bestfit_color, lw=1)\n",
    "        \n",
    "        ax_res[0].plot(d_spec_1.wave[i,j], (d_spec_1.flux[i,j] - LogLike_1.f[i,j]*m_spec_1.flux[i,j]), c='k', lw=0.5)\n",
    "        ax_res[0].plot(d_spec_1.wave[i,j], 0*m_spec_1.flux[i,j], c=bestfit_color, lw=2)\n",
    "    \n",
    "    errorbar_kwargs = {'elinewidth':1.8, 'capsize':2.8, 'capthick':1.8}\n",
    "    ax_res[0].errorbar(\n",
    "        d_spec_1.wave[i].min()-3.5, [0], yerr=np.nanmean(d_spec_1.err[i]), c='k', **errorbar_kwargs\n",
    "        )\n",
    "    #yerr = np.nanmean(\n",
    "    #    np.concatenate([(LogLike_1.beta[i,k]**2 * Cov_1[i,k].cov).diagonal() for k in range(3)])\n",
    "    #    )**(1/2)\n",
    "    yerr = np.nanmean(\n",
    "        np.concatenate([np.sqrt(LogLike_1.beta[i,k]**2 * Cov_1[i,k].cov).diagonal() for k in range(3)])\n",
    "        )\n",
    "    print(np.nanmean(d_spec_1.err[i]) / yerr)\n",
    "    ax_res[0].errorbar(\n",
    "        d_spec_1.wave[i].min()-9.5, [0], yerr=yerr, c=bestfit_color, **errorbar_kwargs\n",
    "        )\n",
    "\n",
    "for i, order in enumerate(orders_for_zoom_in):\n",
    "    ax_spec[i+1].plot(\n",
    "        d_spec_1.wave[order,:].flatten(), d_spec_1.flux[order,:].flatten(), c='k', lw=0.5\n",
    "        )\n",
    "\n",
    "    for j in range(d_spec_1.n_dets):\n",
    "        ax_spec[i+1].plot(d_spec_1.wave[order,j], LogLike_1.f[order,j]*m_spec_1.flux[order,j], c=bestfit_color, lw=2)\n",
    "\n",
    "        ax_res[i+1].plot(d_spec_1.wave[order,j], (d_spec_1.flux[order,j] - LogLike_1.f[order,j]*m_spec_1.flux[order,j]), c='k', lw=0.5)\n",
    "        ax_res[i+1].plot(d_spec_1.wave[order,j], 0*m_spec_1.flux[order,j], c=bestfit_color, lw=2)\n",
    "        \n",
    "    ax_res[i+1].errorbar(\n",
    "        d_spec_1.wave[order].min()-0.5, [0], yerr=np.nanmean(d_spec_1.err[order]), c='k', **errorbar_kwargs\n",
    "        )\n",
    "    #yerr = np.nanmean(\n",
    "    #    np.concatenate([(LogLike_1.beta[i,k]**2 * Cov_1[order,k].cov).diagonal() for k in range(3)])\n",
    "    #    )**(1/2)\n",
    "    yerr = np.nanmean(\n",
    "        np.concatenate([np.sqrt(LogLike_1.beta[i,k]**2 * Cov_1[order,k].cov).diagonal() for k in range(3)])\n",
    "        )\n",
    "    print(yerr)\n",
    "    ax_res[i+1].errorbar(\n",
    "        d_spec_1.wave[order].min()-1.05, [0], yerr=yerr, c=bestfit_color, **errorbar_kwargs\n",
    "        )\n",
    "    \n",
    "    x0 = ax_spec[i+1].get_xlim()[0]\n",
    "    y0 = ax_spec[i+1].get_ylim()[0]\n",
    "    width  = np.abs(ax_spec[i+1].get_xlim()[1] - x0)\n",
    "    height = np.abs(ax_spec[i+1].get_ylim()[1] - y0)\n",
    "    bounds = (x0, y0, width, height)\n",
    "\n",
    "    _, con_patch = ax_spec[0].indicate_inset(\n",
    "        bounds=bounds,\n",
    "        inset_ax=ax_spec[i+1], #inset_ax=None, \n",
    "        edgecolor='k', alpha=0.2, \n",
    "        )\n",
    "    #for con_patch_k in con_patch:\n",
    "    #    con_patch_k.set(zorder=-1, clip_on=False)\n",
    "\n",
    "    height_ratio = gridspec_kw['height_ratios'][-1] / gridspec_kw['height_ratios'][-2]\n",
    "    ax_res_ylim = (-0.5*height_ratio*height, +0.5*height_ratio*height)\n",
    "    ax_res[i+1].set(ylim=ax_res_ylim)\n",
    "    #ax_res_height = np.abs(ax_res[i+1].get_ylim()[1] - ax_res[i+1].get_ylim()[0])\n",
    "\n",
    "    ax_res[i+1].set(xlim=ax_spec[i+1].get_xlim())\n",
    "\n",
    "ax_spec[0].set(ylim=(0,1.4e-14))\n",
    "ax_res[0].set(xlim=ax_spec[0].get_xlim())\n",
    "height = np.abs(np.diff(ax_spec[0].get_ylim()))\n",
    "\n",
    "height_ratio = gridspec_kw['height_ratios'][1] / gridspec_kw['height_ratios'][0]\n",
    "ax_res_ylim = (-0.5*height_ratio*height, +0.5*height_ratio*height)\n",
    "ax_res[0].set(\n",
    "    yticks=np.arange(-6e-16,2*6e-16,6e-16), \n",
    "    yticklabels=np.arange(-6e-16,2*6e-16,6e-16)/1e-14, \n",
    "    ylim=ax_res_ylim, \n",
    "    )\n",
    "ax_res[-1].set(\n",
    "    yticks=np.arange(-6e-16,2*6e-16,6e-16), \n",
    "    yticklabels=np.arange(-6e-16,2*6e-16,6e-16)/1e-15, \n",
    "    )\n",
    "\n",
    "ax[-1].set(xlabel=r'Wavelength (nm)')\n",
    "ax[1].set(ylabel=r'Residuals')\n",
    "ax[0].set(ylabel=r'$F_\\lambda\\ (\\mathrm{erg\\ s^{-1}\\ cm^{-2}\\ nm^{-1}})$')\n",
    "fig.savefig('./plots/bestfit_spec_zoom_ins_new.pdf')\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1604385688606084e-16"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.942660350478406e-16"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nanmean(d_spec_1.err[order,:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crires_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
